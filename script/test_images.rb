#!/usr/bin/env ruby
# Test simple de l'extraction d'images

puts "\n" + "=" * 80
puts "TEST EXTRACTION D'IMAGES"
puts "=" * 80 + "\n"

# Lire l'URL depuis les arguments ou utiliser une URL par dÃ©faut
url = ARGV[0] || "https://www.seloger.com/annonces/achat/appartement/paris-75/ternes-17eme/201234567.htm"

puts "URL testÃ©e : #{url}"
puts "Lancement de l'extraction...\n\n"

# CrÃ©ation du scraper
scraper = PropertyScraperService.new(url, {
  images: true,
  cache: false,
  geocode: false
})

# Extraction
data = scraper.call

# RÃ©sultats
puts "\n" + "=" * 80
puts "RÃ‰SULTATS"
puts "=" * 80

if data
  puts "\nâœ… DonnÃ©es extraites:"
  puts "   - Titre: #{data[:title]}"
  puts "   - Prix: #{data[:price]} â‚¬" if data[:price]
  puts "   - Surface: #{data[:surface]} mÂ²" if data[:surface]
  puts "   - Ville: #{data[:city]}" if data[:city]
else
  puts "\nâŒ Ã‰chec de l'extraction"
end

puts "\nğŸ“¸ Images:"
puts "   Total: #{scraper.image_urls.size} image(s)"

if scraper.image_urls.any?
  scraper.image_urls.each_with_index do |img_url, i|
    # Afficher les 100 premiers caractÃ¨res de chaque URL
    display_url = img_url.length > 100 ? img_url[0..97] + "..." : img_url
    puts "   #{i+1}. #{display_url}"
  end
else
  puts "   âš ï¸  Aucune image trouvÃ©e"
end

if scraper.errors.any?
  puts "\nâŒ Erreurs:"
  scraper.errors.each { |err| puts "   - #{err}" }
end

puts "\nğŸ’¡ Conseil:"
if scraper.image_urls.empty?
  puts "   - VÃ©rifiez les logs avec: tail -f log/development.log | grep Image"
  puts "   - Le site utilise peut-Ãªtre du JavaScript (ajoutez javascript: true)"
  puts "   - L'URL est peut-Ãªtre une redirection (Jinka) qui a expirÃ©"
else
  puts "   âœ… L'extraction d'images fonctionne !"
end

puts "\n" + "=" * 80 + "\n"

