# Import automatique de biens immobiliers

## ğŸ¯ FonctionnalitÃ©

Cette fonctionnalitÃ© permet d'importer automatiquement les informations d'un bien immobilier en collant simplement le lien de l'annonce.

## ğŸŒ Sites supportÃ©s

- **Jinka** (redirections) - ex: `https://api.jinka.fr/apiv2/alert/redirect_preview?token=...`
- **SeLoger**
- **LeBonCoin**
- **PAP (De Particulier Ã  Particulier)**
- **Bien'ici**
- **Sites gÃ©nÃ©riques** (avec extraction basique)

## ğŸ“‹ DonnÃ©es extraites

Le service tente d'extraire automatiquement :

- âœ… Titre de l'annonce
- âœ… Prix affichÃ©
- âœ… Surface (mÂ²)
- âœ… Nombre de piÃ¨ces
- âœ… Nombre de chambres
- âœ… Ville
- âœ… Code postal
- âœ… Type de bien (appartement, maison, etc.)
- âœ… Classe Ã©nergÃ©tique (DPE)
- âœ… Ã‰missions GES

## ğŸš€ Utilisation

### Interface utilisateur

1. Allez sur la page "Nouveau bien" ou "Modifier un bien"
2. En haut du formulaire, vous verrez une section "Import automatique"
3. Collez le lien de l'annonce dans le champ
4. Cliquez sur "Importer depuis l'URL"
5. Les donnÃ©es seront automatiquement remplies dans le formulaire
6. VÃ©rifiez et complÃ©tez les informations manquantes
7. Enregistrez le bien

### Exemples de liens

```
https://api.jinka.fr/apiv2/alert/redirect_preview?token=4f90eddfeba4e87268ee03eae18d485a&ad=73850207
https://api.jinka.fr/apiv2/alert/redirect_preview?token=48554022be2e86db2b13adb6132414d0&ad=90898543
https://www.seloger.com/annonces/achat/appartement/paris-75/12345.htm
https://www.leboncoin.fr/ventes_immobilieres/12345.htm
```

## ğŸ”§ Architecture technique

### Service : `PropertyScraperService`

Le service principal qui gÃ¨re l'extraction des donnÃ©es.

**MÃ©thodes principales :**

- `call` : Point d'entrÃ©e principal, retourne un Hash avec les donnÃ©es extraites
- `resolve_jinka_redirect` : RÃ©sout les redirections Jinka
- `extract_from_*` : MÃ©thodes spÃ©cifiques par site

**Utilisation :**

```ruby
scraper = PropertyScraperService.new(url)
property_data = scraper.call

if property_data
  property.update(property_data)
else
  puts scraper.errors
end
```

### ContrÃ´leur : `PropertiesController#import_from_url`

Action qui expose le service via une API JSON.

**Route :** `POST /properties/import_from_url`

**ParamÃ¨tres :**
```json
{
  "url": "https://..."
}
```

**RÃ©ponse succÃ¨s :**
```json
{
  "success": true,
  "data": {
    "title": "Bel appartement T3",
    "price": 350000,
    "surface": 65.0,
    "rooms": 3,
    ...
  }
}
```

**RÃ©ponse erreur :**
```json
{
  "error": "Message d'erreur"
}
```

### ContrÃ´leur Stimulus : `property-importer`

GÃ¨re l'interface utilisateur et les appels AJAX.

**Targets :**
- `urlInput` : Champ de saisie de l'URL
- `importButton` : Bouton d'import
- `status` : Zone d'affichage des messages
- `form` : Formulaire Ã  remplir

**Actions :**
- `importFromUrl` : Lance l'import et remplit le formulaire

## ğŸ›  AmÃ©liorations futures

### Court terme
- [ ] Ajouter un systÃ¨me de cache pour Ã©viter de re-scraper la mÃªme URL
- [ ] AmÃ©liorer l'extraction des adresses complÃ¨tes
- [ ] Extraire les photos de l'annonce
- [ ] GÃ©rer plus de champs (Ã©tage, ascenseur, etc.)

### Moyen terme
- [ ] Ajouter un systÃ¨me d'API officielle avec des partenaires
- [ ] Utiliser des services tiers (Bright Data, ScrapingBee)
- [ ] Ajouter la dÃ©tection automatique du type de bien
- [ ] Extraire les frais d'agence

### Long terme
- [ ] IA pour amÃ©liorer l'extraction
- [ ] Historique des prix pour dÃ©tecter les baisses
- [ ] Alertes sur les modifications d'annonces
- [ ] Extension navigateur pour import en un clic

## âš ï¸ Limitations et considÃ©rations

### LÃ©gales
- Le scraping doit respecter les CGU des sites
- Utiliser uniquement pour un usage personnel
- Ne pas surcharger les serveurs cibles
- Respecter le fichier robots.txt

### Techniques
- Les sites peuvent changer leur structure HTML
- Certains sites utilisent du JavaScript lourd (nÃ©cessite un navigateur headless)
- Les APIs peuvent bloquer les requÃªtes automatisÃ©es
- Timeout de 10 secondes par requÃªte

### FiabilitÃ©
- Toujours vÃ©rifier les donnÃ©es extraites
- Certains champs peuvent ne pas Ãªtre dÃ©tectÃ©s
- La qualitÃ© dÃ©pend de la structure du site source

## ğŸ§ª Tests

Pour tester le service :

```ruby
# Console Rails
scraper = PropertyScraperService.new("https://...")
result = scraper.call
puts result.inspect
puts scraper.errors if result.nil?
```

## ğŸ“ Notes de dÃ©veloppement

### Ajout d'un nouveau site

Pour ajouter le support d'un nouveau site :

1. Ajouter un pattern dans `PropertyScraperService` :
```ruby
NOUVEAUSITE_PATTERN = %r{nouveausite\.com}
```

2. Ajouter le cas dans la mÃ©thode `call` :
```ruby
when NOUVEAUSITE_PATTERN
  extract_from_nouveausite(resolved_url)
```

3. ImplÃ©menter les mÃ©thodes d'extraction :
```ruby
def extract_from_nouveausite(url)
  html = fetch_html(url)
  return nil unless html

  {
    title: extract_nouveausite_title(html),
    price: extract_nouveausite_price(html),
    # ...
  }.compact
end
```

### Debugging

Activer les logs dÃ©taillÃ©s :
```ruby
# config/environments/development.rb
config.log_level = :debug
```

VÃ©rifier les requÃªtes HTTP dans les logs Rails.

